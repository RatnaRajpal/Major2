{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07a47121",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import contractions\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import snscrape.modules.twitter as sntwitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3efed908",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2084c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets(username):\n",
    "    tweets = []\n",
    "    for i, tweet in enumerate(sntwitter.TwitterSearchScraper(f'from:{username}').get_items()):\n",
    "        tweets.append(tweet.content)\n",
    "        if i == 50: break\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8718701",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_files():\n",
    "    try:\n",
    "        with open(\"../server/models/RandomForest_E-I.sav\", \"rb\") as file:\n",
    "            ei_classifier = pickle.load(file)\n",
    "        with  open(\"../server/models/RandomForest_N-S.sav\", \"rb\") as file:\n",
    "            ns_classifier = pickle.load(file)\n",
    "        with open(\"../server/models/RandomForest_F-T.sav\", \"rb\") as file:\n",
    "            ft_classifier = pickle.load(file)\n",
    "        with  open(\"../server/models/RandomForest_J-P.sav\", \"rb\") as file:\n",
    "            jp_classifier = pickle.load(file)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Model not found!\")\n",
    "\n",
    "    try:\n",
    "        with open(\"../server/models/vectorizer.pkl\", \"rb\") as file:\n",
    "            vectorizer = pickle.load(file)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Tokenizer not found!\")\n",
    "\n",
    "    return ei_classifier, ns_classifier, ft_classifier, jp_classifier, vectorizer\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7872c56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    stopword_list = stopwords.words(\"english\")\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    text = contractions.fix(text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'@([a-zA-Z0-9_]{1,50})', '', text)\n",
    "    text = re.sub(r'#([a-zA-Z0-9_]{1,50})', '', text)\n",
    "    text = re.sub(r'http[s]?://\\S+', '', text)\n",
    "    text = re.sub(r'[^A-Za-z0-9]+', ' ', text)\n",
    "    text = re.sub(r' +', ' ', text)\n",
    "    text = \" \".join([word for word in text.split() if not len(word) <3])\n",
    "    text = word_tokenize(text)\n",
    "    text = [word for word in text if not word in stopword_list]\n",
    "    text = [lemmatizer.lemmatize(word) for word in text]\n",
    "    text = \" \".join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "683a54e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(username,tweet=[]):\n",
    "    ei_classifier, ns_classifier, ft_classifier, jp_classifier, vectorizer = load_files()\n",
    "    if(len(tweet)==0):\n",
    "        tweets = get_tweets(username)\n",
    "    else:\n",
    "        tweets=tweet\n",
    "      \n",
    "    text   = \" \".join(tweets)\n",
    "    text   = preprocessing(text)\n",
    "    text   = vectorizer.transform([text])\n",
    "    \n",
    "    prediction = \"\"\n",
    "    e_or_i = \"E\" if ei_classifier.predict(text)[0] == 1 else \"I\"\n",
    "    n_or_s = \"N\" if ns_classifier.predict(text)[0] == 1 else \"S\"\n",
    "    f_or_t = \"F\" if ft_classifier.predict(text)[0] == 1 else \"T\"\n",
    "    j_or_p = \"J\" if jp_classifier.predict(text)[0] == 1 else \"P\"\n",
    "    prediction = e_or_i + n_or_s + f_or_t + j_or_p\n",
    "\n",
    "    return prediction, tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0879b1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.0.2 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.0.2 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator SVC from version 1.0.2 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator TfidfTransformer from version 1.0.2 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 1.0.2 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('INFJ',\n",
       " [\"I was shocked to wake up to the news this morning. A reversal of Roe v. Wade would set us back 50 years and disproportionately impact the most vulnerable women in society.\\n\\nI support a woman's right to make their own decisions about their health care.\",\n",
       "  'My new book comes out tomorrow – but @GatesNotes Insiders can get an early sneak peek and download a free chapter now: https://t.co/6cQv2FwB4W https://t.co/QwbjHOnywy',\n",
       "  'No one wants to live through this again – and we don’t have to. As @larrybrilliant says: Outbreaks are inevitable, but pandemics are optional. https://t.co/RSdJCbDyd3',\n",
       "  'I’ve been lucky to spend time with, and learn from, many extraordinary teachers over the years, like these incredible Washington State teachers. I appreciate their dedication and resilience. #TeacherAppreciationWeek https://t.co/aZeLqEKFkz',\n",
       "  'The world can make COVID-19 the last pandemic: https://t.co/b3bHaQ3eLr https://t.co/wnKIfARZzh',\n",
       "  'The world wasn’t ready for COVID, but we can choose to be ready next time. https://t.co/ghjikJDkPf',\n",
       "  'I’m excited to chat with one of my favorite thinkers @FareedZakaria next week at @92Y! https://t.co/5tkkpBucjA',\n",
       "  'To avoid another COVID-19 – or worse – the world needs a full-time, paid team whose entire job is to prevent pandemics. I call it GERM: https://t.co/jvpjjg1jUY',\n",
       "  'I’m looking forward to this chat with @amolrajan at @howtoacademy and @penguinlive. https://t.co/mw5OF9f8Aq',\n",
       "  'The best way to prevent pneumonia is to vaccinate children against the pathogens that cause it. This is an impressive effort. #LongLifeForAll @MoHFW_INDIA https://t.co/G1TOdGuDnZ',\n",
       "  'Giving a TED talk is always a memorable (and nerve-wracking!) experience. Beyond the talk, I also got to listen to the stories of frontline workers and catch up with some of the people working to make the world a more equitable place: https://t.co/dTRJk1uJGM',\n",
       "  'Each day, polio workers around the world cross mountains and deserts to bring vaccines to kids. It’s up to us to match their dedication with our support. #EndPolio https://t.co/zfnxgjKT6A',\n",
       "  'Building a software company is nothing compared to building a Roman fire bucket. I tried my hand at it for my latest TED Talk: https://t.co/kKsR0yKIhV https://t.co/cV9lphEFtO',\n",
       "  'The Global Fund is one of the kindest things people have ever done for one another. Replenishing it will lower malaria cases by almost two thirds in just four years, strengthen health systems, and help ensure COVID-19 is the last pandemic. #WorldMalariaDay https://t.co/cEKaxoI2Pv',\n",
       "  'Happy World Book Day! I try to read every day, whether I have a busy day at the office or am out for a hike. It’s one of my favorite ways to learn new things and better understand the world. https://t.co/cW71Lsv8Zr',\n",
       "  'Seven years ago, I gave a TED Talk about how the world wasn’t ready for the next epidemic. A lot has changed since then: https://t.co/3oT8MJIYrO',\n",
       "  'We can’t reach zero carbon emissions without innovation. In this new series, you’ll meet some people who are on the cutting edge of clean energy: \\n#EarthDay https://t.co/o6CISr0GD2',\n",
       "  'Interesting article on how Liberia’s health workers use data to provide crucial insights and stop diseases from spreading: https://t.co/vKT5si3kHR',\n",
       "  'I hope Namzi is feeling better. Her comics are great! https://t.co/P8nKWRy4bY',\n",
       "  'One of the surprises of the pandemic is how long it took to develop effective treatments—few people thought there would be vaccines before COVID medicines. In this first excerpt from my new book I suggest ways to speed things up during future outbreaks. https://t.co/ShtJkmrPbC',\n",
       "  'This rocks. https://t.co/ASw6Zsvo2Z',\n",
       "  \"One of the best parts of my job is learning from innovators and entrepreneurs taking on some of the world's greatest challenges. They make me optimistic about the world’s ability to get to net-zero carbon emissions: https://t.co/1wNjdBJOlJ\",\n",
       "  \"Preventing the next pandemic is not cheap, but it'll save lives and money in the long run. The IMF estimates that COVID will cost nearly $14 trillion. We can save trillions by spending billions. https://t.co/uaIhdLHD4u\",\n",
       "  'This week, I got to do what every nerd dreams of – talk about ideas and learn from others doing big things. I believe that with good ideas and collaboration, we can make COVID the last pandemic. \\n \\nPlus, it’s not every day you can say thanks for coming to my TED Talk. https://t.co/1qAx64z334',\n",
       "  'By May of 2021, more than 115,000 frontline workers died taking care of COVID patients. At #TED2022, we discussed lessons learned that will help us be smarter next time, and not repeat the past. https://t.co/Ef3jLHIrrw',\n",
       "  \"I'm excited to take the stage at #TED2022 and share a plan to make COVID-19 the last pandemic. https://t.co/0Xvs6v2vsX\",\n",
       "  'I recently had a chance to check out some of the latest devices and experiences in augmented reality. It was a lot of fun to see how far the hardware has come. https://t.co/vfZfALQuXV',\n",
       "  'Solving for Zero is an excellent overview of the complex challenge of climate change and an inspiring look at some of the most promising solutions. I’m glad I got to be a part of it and encourage you to take a look: https://t.co/xuAJIV6c42 https://t.co/Lyi1UshH9j',\n",
       "  'The latest #ClimateReport is an important reminder of the work ahead. I’m especially encouraged by the focus on the breakthroughs we need to avoid a climate disaster. (The word “innovation” appears 4,989 times!) https://t.co/U1xJ7Xqzm7',\n",
       "  'No one was a better or more tireless advocate for improving global health than Paul. https://t.co/TV6KVUOLx7',\n",
       "  'Bed nets might be simple tools, but they’re one of the best weapons against malaria. https://t.co/mZuC4uQyJR',\n",
       "  'There’s a lot to learn from poop: https://t.co/5BhkSraHgQ',\n",
       "  'Bono is humanity’s rock star and I’m fortunate to call him my friend. Congratulations on this well-deserved recognition. https://t.co/QssGXMeBdv',\n",
       "  'Wild polio virus returning to Malawi reminds us that strong health systems are critical for ending disease, stopping re-emergence of diseases we thought were gone, and preventing new diseases from spreading: https://t.co/iczu84yaKp',\n",
       "  'Young people are right – it’s not too late to avoid a climate disaster: https://t.co/AsniMSbEv6',\n",
       "  'What a lovely bake, Ruby. You deserve a Paul Hollywood handshake for that one! https://t.co/XwRzaQwkNC',\n",
       "  'I have enough nostalgia to go around. John Roach was a true pioneer of the industry, and I’m grateful to have known him. https://t.co/9ZbkcYYGOD',\n",
       "  'Changing mindsets is never easy, but Sudha Varghese empowers girls to believe in themselves and see their potential for greatness: https://t.co/IJ0LM8wJHd https://t.co/qOR3gsGV6s',\n",
       "  'In February 2020, we had a degree of optimism that the world was better prepared to respond to COVID-19. Two years later, we gathered to discuss lessons learned that might help us prevent the next pandemic. https://t.co/k5zZndEebw',\n",
       "  'A world without tuberculosis is attainable if we deliver effective diagnostics &amp; treatment to all who need it. Fully funding The Global Fund will get us on track to end TB and save 20 million more lives. https://t.co/1PbBpDBls8',\n",
       "  'Madeleine Albright made history in so many ways during her lifetime, including as the first female Secretary of State. Today the world lost an advocate for peace and a visionary who believed in our common humanity. https://t.co/oOvw2bjYIG',\n",
       "  'Every day I’m reminded of how my dad’s wisdom, generosity, and compassion lives on in the many people he influenced and inspired around the world: https://t.co/JfsS3Go37B https://t.co/AuO43mvGOF',\n",
       "  'Sudha Varghese runs a school in Bihar, India that teaches students how to stand up for themselves and see their own potential for greatness. https://t.co/dlicoBdTRJ https://t.co/bs39Ia6PvJ',\n",
       "  'Shumaila Rehamani is a polio vaccinator in Pakistan. She talks with families and community leaders to answer all their questions about the importance of vaccination. She makes sure every child in her community is protected from this disease. https://t.co/jfhzKmjqia https://t.co/924Ban8ONT',\n",
       "  'Mamello Makhele is a nurse-midwife working to improve health care for women in rural Lesotho, where there are high rates of maternal mortality. Thanks to her incredible work, many women are healthier today in Lesotho. https://t.co/NVGya9UAf8',\n",
       "  'Brooke Brown, the 2021 Washington State Teacher of the Year, helps high school seniors explore their identity. She is a phenomenal teacher and was kind enough to show me one of her favorite lessons to teach. https://t.co/Niw2gPMxCl https://t.co/PfLAqkplQh',\n",
       "  'Kakenya Ntaiya founded @KakenyasDream to enable girls’ education and end harmful traditional practices like child marriage. Her story is a powerful example of how one person’s act of bravery can spark dramatic change. https://t.co/qrEJrqOrwD https://t.co/209Cx2e266',\n",
       "  \"I've been lucky to meet and learn from so many changemakers. These incredible women continue to inspire me. ⬇️\",\n",
       "  'One of the most significant ways my dad’s spirit continues is through the @Gates_Cambridge Scholarship. Of all the grants he was involved in at our foundation, this one was always his favorite. https://t.co/1oFsiEllxn',\n",
       "  'By acting now and funding organizations like @CEPIvaccines, we can help ensure the world never again experiences the hardship of a pandemic. I’m encouraged by the new commitments to groundbreaking R&amp;D made at the Global Pandemic Preparedness Summit. https://t.co/KedWbFzTaC',\n",
       "  'In a crisis, we can always look for the helpers—the people who are putting their lives on the line to aid refugees and victims of the invasion—and support them. I’m proud to support the UN’s refugee agency and urge the global community to do the same. https://t.co/5fkRU6UmCK'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prediction(\"billgates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "687adc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "class TwitterClient(object):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        #API KEY\n",
    "        self.ckey='9dWxuFf6svWFW9XUP63xHEYMf' \n",
    "        #API SECRET\n",
    "        self.csecret='Zkn65SEWsdpHbiBnnHStlOFcJD67KBDJOvdWDYJlGQLzShXA7u'\n",
    "        #ACCESS TOKEN\n",
    "        self.atoken='1015294450006757376-vmsspbAxG1yWnDHL65e7XqwtNYIPWd'\n",
    "        #ACCESS SECRET\n",
    "        self.asecret='xm2QnNP5vgeUvU7waASVOh9UlYUwj3zbeurkctBkPfDmU'\n",
    "\n",
    "        try:\n",
    "          \n",
    "            auth=tweepy.OAuthHandler(self.ckey, self.csecret)\n",
    "            auth.set_access_token(self.atoken, self.asecret)\n",
    "            self.api=tweepy.API(auth)\n",
    "            \n",
    "        except tweepy.TweepError as e:\n",
    "            print(f\"Error: Twitter Authentication Failed - \\n{str(e)}\") \n",
    "\n",
    "    def get_user_tweets(self, user):\n",
    "        username = user\n",
    "        count = 100\n",
    "\n",
    "        try:\n",
    "            # Create query method using parameters\n",
    "            tweets = tweepy.Cursor(self.api.user_timeline,screen_name=username).items(count)\n",
    "            \n",
    "            # Pull information from tweets iterable object\n",
    "            tweets_list = [[tweet.text] for tweet in tweets]\n",
    "\n",
    "            # Create dataframe from tweets list\n",
    "            tweets_df = pd.DataFrame(tweets_list)\n",
    "            #print(tweets_df)\n",
    "            return tweets_df\n",
    "           \n",
    "        except BaseException as e:\n",
    "            print('failed on_status,',str(e))\n",
    "            time.sleep(3)\n",
    "\n",
    "    def get_user_followers(self,user):\n",
    "        # to fetch 5 following of the user and their personality types\n",
    "        username = user\n",
    "        follower_ids = []\n",
    "        nfollowers = 5\n",
    "        #print (\"Getting following...\")\n",
    "        users = tweepy.Cursor(self.api.get_friends,screen_name = username,count=nfollowers).items(nfollowers)\n",
    "        tweets_list = []\n",
    "        for user in users:\n",
    "            # tweet_user = []\n",
    "            #print (\"Adding following...\")\n",
    "            try:\n",
    "                follower_ids.append(user.screen_name)\n",
    "                tweets = tweepy.Cursor(self.api.user_timeline,screen_name=user.screen_name).items(100)\n",
    "                # print ([tweet.text for tweet in tweets])\n",
    "                tweets_list.append([tweet.text for tweet in tweets])\n",
    "            except tweepy.errors.TweepError as e:\n",
    "                print (e)\n",
    "                time.sleep(60)\n",
    "        #print (follower_ids)\n",
    "        tweet_df = pd.DataFrame({'follower':follower_ids})\n",
    "        tweet_df[\"tweets\"] = pd.Series(tweets_list)\n",
    "        #print (follower_ids)\n",
    "        #print(tweet_df)\n",
    "        return tweet_df\n",
    "\n",
    "def tweet_return(tweet_handle):\n",
    "    twitter = TwitterClient()\n",
    "\n",
    "    tweet_path = os.path.join(\"../server/Dataset/\", \"tweets_\"+str(tweet_handle)+\".csv\")\n",
    "    tweet_follower_path = os.path.join(\"../server/Dataset/\",\"follower_\"+str(tweet_handle)+\".csv\")\n",
    "\n",
    "    #tweet_path = \"/MyDrive/MyDrive/MajorFinal/datasets/twitter_data/\"+\"tweets_\"+str(tweet_handle)+\".csv\"\n",
    "    #tweet_fol_path = \"/MyDrive/MyDrive/MajorFinal/datasets/twitter_data/\"+\"fol_\"+str(tweet_handle)+\".csv\"\n",
    "    twitter.get_user_tweets(str(tweet_handle)).to_csv(tweet_path)\n",
    "    twitter.get_user_followers(str(tweet_handle)).to_csv(tweet_follower_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ac6e6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_return(\"billgates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e1c4175",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "maxlen = 1500\n",
    "per_types = ['ENFJ','ENFP','ENTJ','ENTP','ESFJ','ESFP','ESTJ','ESTP','INFJ','INFP','INTJ','INTP','ISFJ','ISFP','ISTJ','ISTP']\n",
    "\n",
    "def clean_text(text):\n",
    "    regex = re.compile('[%s]' % re.escape('|'))\n",
    "    text = regex.sub(\" \", text)\n",
    "    words = str(text).split()\n",
    "    words = [i.lower() + \" \" for i in words]\n",
    "    words = [i for i in words if not \"http\" in i]\n",
    "    words = \" \".join(words)\n",
    "    words = words.translate(words.maketrans('', '', string.punctuation))\n",
    "    return words\n",
    "\n",
    "def predict_type(text):\n",
    "    cleaned_ip = clean_text(text)\n",
    "    #custom_test_ids = [tokenizer.encode(str(cleaned_ip))]\n",
    "    #type_ind = np.argmax(new_model.predict(np.array(custom_test_ids)))\n",
    "    return get_prediction(\"abc\",[cleaned_ip])[0]\n",
    "\n",
    "def predict_tweet(username):\n",
    "    get_prediction(username)\n",
    "    \n",
    "    per_op = get_prediction(username)[0]\n",
    "\n",
    "    op_json = {}\n",
    "    op_json[\"name\"] = str(username)\n",
    "    op_json[\"type\"] = str(per_op)\n",
    "    info_df = pd.read_csv(\"../server/Dataset/MBTI.csv\")\n",
    "\n",
    "    #print(per_op)\n",
    "    #print(info_df)\n",
    "    op_json[\"traits\"] = info_df[info_df[\"type\"]==per_op][\"traits\"].values[0]\n",
    "    op_json[\"career\"] = info_df[info_df[\"type\"]==per_op][\"career\"].values[0]\n",
    "    op_json[\"people\"] = info_df[info_df[\"type\"]==per_op][\"eminent personalities\"].values[0]\n",
    "    op_json[\"per_name\"] = info_df[info_df[\"type\"]==per_op][\"name\"].values[0]\n",
    "    perfile = open(\"../server/static/results.js\",\"w\")\n",
    "    perstr = \"var personality_data=\"+str(op_json)+\"\\n\"\n",
    "    perfile.write(perstr)\n",
    "    perfile.close()\n",
    "    print(op_json)\n",
    "    return op_json\n",
    "\n",
    "def predict_follow(username):\n",
    "    twitter = TwitterClient()\n",
    "    follow_df = twitter.get_user_followers(str(username))\n",
    "    follow_json = {}\n",
    "    follow_ids = {}\n",
    "    for i in range(5):\n",
    "        list_j = follow_df.tweets.iloc[i]\n",
    "        new_list = []\n",
    "        for j in list_j:\n",
    "            new_list.append(clean_text(j))\n",
    "        print(get_prediction(follow_df.follower.iloc[i],new_list)[0])\n",
    "    \n",
    "        tweet_ind = get_prediction(follow_df.follower.iloc[i],new_list)[0]\n",
    "        follow_json[str(i)] = tweet_ind\n",
    "        follow_ids[str(i)] = follow_df.follower.iloc[i]\n",
    "        perfile = open(\"../server/static/results2.js\",\"w\")\n",
    "        perstr = \"var follower_data=\"+str(follow_json)+\"\\n\"\n",
    "        folstr = \"var follower_ids=\"+str(follow_ids)+\"\\n\"\n",
    "        perfile.write(perstr)\n",
    "        perfile.write(folstr)\n",
    "        perfile.close()\n",
    "    return follow_json\n",
    "#predict_tweet(\"simran\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9c03143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'simran', 'type': 'INFP', 'traits': 'Creative, Independent, Adaptable, Inquisitive, Caring', 'career': 'Writer, Bureaucrat, Social Worker, Psychologist, Teacher', 'people': 'William Shakespeare, Vincent Van Gogh, Hellen Keller, John Mayer', 'per_name': 'Mediator'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'simran',\n",
       " 'type': 'INFP',\n",
       " 'traits': 'Creative, Independent, Adaptable, Inquisitive, Caring',\n",
       " 'career': 'Writer, Bureaucrat, Social Worker, Psychologist, Teacher',\n",
       " 'people': 'William Shakespeare, Vincent Van Gogh, Hellen Keller, John Mayer',\n",
       " 'per_name': 'Mediator'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_tweet(\"simran\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d648ebcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [03/May/2022 22:21:23] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [03/May/2022 22:21:24] \"GET /static/assets/vendor/venobox/venobox.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:21:24] \"GET /static/assets/vendor/remixicon/remixicon.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:21:24] \"GET /static/assets/vendor/bootstrap/css/bootstrap.min.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:21:24] \"GET /static/assets/vendor/aos/aos.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:21:24] \"GET /static/assets/css/style.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:21:24] \"GET /static/assets/vendor/boxicons/css/boxicons.min.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:21:24] \"GET /static/assets/vendor/jquery/jquery.min.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:21:24] \"GET /static/assets/vendor/icofont/icofont.min.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:21:24] \"GET /static/assets/vendor/bootstrap/js/bootstrap.bundle.min.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:21:24] \"GET /static/assets/vendor/jquery.easing/jquery.easing.min.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:21:24] \"GET /static/assets/vendor/owl.carousel/assets/owl.carousel.min.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:21:24] \"GET /static/assets/vendor/php-email-form/validate.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:21:24] \"GET /static/assets/vendor/venobox/venobox.min.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:21:24] \"GET /static/assets/vendor/waypoints/jquery.waypoints.min.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:21:24] \"GET /static/assets/js/main.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:21:24] \"GET /static/assets/vendor/counterup/counterup.min.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:21:24] \"GET /static/assets/vendor/aos/aos.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:21:24] \"GET /static/assets/vendor/owl.carousel/owl.carousel.min.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:21:24] \"GET /static/assets/img/MBTIImg1.png HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:21:24] \"GET /static/assets/img/cogfunc.png HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:21:25] \"GET /static/assets/img/hero-bg.jpg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:21:25] \"GET /static/assets/vendor/boxicons/fonts/boxicons.woff2 HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:21:27] \"GET /static/assets/vendor/icofont/fonts/icofont.woff2 HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:21:54] \"POST /tweet_pred HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'elonmusk', 'type': 'INTP', 'traits': 'Conceptual, Complex, Intellectual, Critical, Ingenious', 'career': 'Programmer, Computer Scientist, Web Developer, Composer, Economist, Scientist', 'people': 'Larry Page, Albert Einstein, Charles Darwin, Abraham Lincoln, ', 'per_name': 'Logician'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/May/2022 22:23:07] \"GET /tweet_pred HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [03/May/2022 22:23:07] \"GET /static/assets2/vendors/iconfonts/mdi/css/materialdesignicons.min.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:23:07] \"GET /static/assets2/vendors/iconfonts/ionicons/dist/css/ionicons.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:23:07] \"GET /static/assets2/vendors/iconfonts/flag-icon-css/css/flag-icon.min.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:23:07] \"GET /static/assets2/vendors/css/vendor.bundle.base.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:23:07] \"GET /static/assets2/vendors/css/vendor.bundle.addons.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:23:07] \"GET /static/assets2/css/shared/style.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:23:07] \"GET /static/assets2/css/demo_1/style.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:23:07] \"GET /static/results2.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:23:07] \"GET /static/results.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [03/May/2022 22:23:07] \"GET /static/assets2/vendors/js/vendor.bundle.base.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:23:07] \"GET /static/assets2/vendors/js/vendor.bundle.addons.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:23:07] \"GET /static/assets2/js/shared/off-canvas.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:23:07] \"GET /static/assets2/js/shared/misc.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:23:07] \"GET /static/assets2/js/demo_1/dashboard.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:23:07] \"GET /static/assets2/images/career/pic-1.png HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:23:07] \"GET /static/assets2/images/career/pic-2.png HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:23:07] \"GET /static/assets2/images/career/pic-7.png HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:23:07] \"GET /static/assets2/images/faces-clipart/pic-1.png HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:23:07] \"GET /static/assets2/images/career/pic-6.png HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:23:07] \"GET /static/assets2/images/faces-clipart/pic-2.png HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:23:07] \"GET /static/assets2/images/faces-clipart/pic-3.png HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:23:07] \"GET /static/assets2/images/faces-clipart/pic-4.png HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:23:07] \"GET /static/assets2/vendors/iconfonts/mdi/fonts/materialdesignicons-webfont.woff2?v=3.3.92 HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:37:53] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [03/May/2022 22:37:53] \"GET /static/assets/vendor/bootstrap/css/bootstrap.min.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:37:53] \"GET /static/assets/vendor/icofont/icofont.min.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:37:54] \"GET /static/assets/vendor/boxicons/css/boxicons.min.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:37:54] \"GET /static/assets/vendor/venobox/venobox.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:37:54] \"GET /static/assets/vendor/remixicon/remixicon.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:37:54] \"GET /static/assets/vendor/owl.carousel/assets/owl.carousel.min.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:37:54] \"GET /static/assets/vendor/aos/aos.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:37:54] \"GET /static/assets/css/style.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:37:54] \"GET /static/assets/vendor/jquery/jquery.min.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:37:54] \"GET /static/assets/vendor/bootstrap/js/bootstrap.bundle.min.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:37:54] \"GET /static/assets/vendor/jquery.easing/jquery.easing.min.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:37:54] \"GET /static/assets/vendor/php-email-form/validate.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:37:54] \"GET /static/assets/vendor/venobox/venobox.min.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:37:54] \"GET /static/assets/vendor/waypoints/jquery.waypoints.min.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:37:54] \"GET /static/assets/vendor/counterup/counterup.min.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:37:54] \"GET /static/assets/vendor/owl.carousel/owl.carousel.min.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:37:54] \"GET /static/assets/vendor/aos/aos.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:37:54] \"GET /static/assets/vendor/boxicons/fonts/boxicons.woff2 HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:37:54] \"GET /static/assets/img/hero-bg.jpg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:37:54] \"GET /static/assets/img/cogfunc.png HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:37:54] \"GET /static/assets/img/MBTIImg1.png HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:37:54] \"GET /static/assets/js/main.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:37:55] \"GET /static/assets/vendor/icofont/fonts/icofont.woff2 HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [03/May/2022 22:38:18] \"POST /tweet_pred HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': '', 'type': 'INTP', 'traits': 'Conceptual, Complex, Intellectual, Critical, Ingenious', 'career': 'Programmer, Computer Scientist, Web Developer, Composer, Economist, Scientist', 'people': 'Larry Page, Albert Einstein, Charles Darwin, Abraham Lincoln, ', 'per_name': 'Logician'}\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, request, redirect, url_for,jsonify\n",
    "from flask_cors import CORS\n",
    "\n",
    "\n",
    "app = Flask(__name__, static_folder=\"static\")\n",
    "#CORS(app)\n",
    "\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template('homepage.html')\n",
    "\n",
    "@app.route('/predict', methods=['GET', 'POST'])\n",
    "def testfn():\n",
    "    # GET request\n",
    "    if request.method == 'GET':\n",
    "        message = {'greeting':'Hello from Flask!'}\n",
    "        return jsonify(message)  # serialize and use JSON headers\n",
    "    # POST request\n",
    "    if request.method == 'POST':\n",
    "        data = request.get_json()  # parse as JSON\n",
    "        user_text = data[\"data\"]\n",
    "        user_type = predict_type(user_text)\n",
    "        return jsonify({\"type\":str(user_type)}),200\n",
    "\n",
    "@app.route('/tweet_pred', methods=['GET', 'POST'])\n",
    "def tweet():\n",
    "    # GET request\n",
    "    if request.method == 'GET':\n",
    "        return render_template('dashboard.html')\n",
    "    # POST request\n",
    "    if request.method == 'POST':\n",
    "        data = request.get_json()  # parse as JSON\n",
    "        user_handle = data[\"handle\"]\n",
    "        tweet_return(user_handle)\n",
    "        user_type = predict_tweet(user_handle)\n",
    "        #render_template('result.html')\n",
    "        return jsonify(user_type),200\n",
    "\n",
    "@app.route('/follow_pred', methods=['GET', 'POST'])\n",
    "#endpoint to fetch user followers\n",
    "def follow_tweet():\n",
    "    # GET request\n",
    "    if request.method == 'GET':\n",
    "        message = {'greeting':'Hello from Flask!'}\n",
    "        return jsonify(message)  # serialize and use JSON headers\n",
    "    # POST request\n",
    "    if request.method == 'POST':\n",
    "        data = request.get_json()  # parse as JSON\n",
    "        user_handle = data[\"handle\"]\n",
    "        # tweet_return(user_handle)\n",
    "        user_type = predict_follow(user_handle)\n",
    "        return jsonify({\"type\":str(user_type)}),200\n",
    "\n",
    "if __name__ == '__main__' :\n",
    "    app.config['TEMPLATES_AUTO_RELOAD'] = True\n",
    "    app.config['SEND_FILE_MAX_AGE_DEFAULT'] = 0\n",
    "    app.run(debug=False, port=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c695ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94032430",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
